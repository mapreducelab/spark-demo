hr.spark.master = "local"
hr.spark.session-config {
    "spark.hadoop.fs.s3a.impl" = "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.fs.s3a.path.style.access" = "false"
    "spark.hadoop.fs.s3a.aws.credentials.provider" = "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,com.amazonaws.auth.EnvironmentVariableCredentialsProvider,com.amazonaws.auth.InstanceProfileCredentialsProvider")
    "spark.hadoop.fs.s3a.connection.ssl.enabled" = "false"
    "fs.alluxio.impl" = "alluxio.hadoop.FileSystem"
    # access key, secret, endpoint might be defined in the config file or extracted fro the env variables.
    // "spark.hadoop.fs.s3a.access.key" = ""
    // "spark.hadoop.fs.s3a.secret.key" = ""
    // "spark.hadoop.fs.s3a.endpoint" = ""
  }


hr.emp-source = "s3a://mapreducelabs/spark/demo/hr/emp/emp.csv"
hr.emp-target = "alluxio://xxx:19998/emp/emp.csv"



