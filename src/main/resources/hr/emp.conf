hr.spark.master = "local"
hr.spark.session-config {
    "spark.hadoop.fs.s3a.impl" = "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.fs.s3a.path.style.access" = "false"
    "spark.hadoop.fs.s3a.aws.credentials.provider" = "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,com.amazonaws.auth.EnvironmentVariableCredentialsProvider,com.amazonaws.auth.InstanceProfileCredentialsProvider")
    "spark.hadoop.fs.s3a.connection.ssl.enabled" = "false"
    # The alluxio-1.7.1-client.jar should be placed in the classpath.
    # Alluxio hadoop distribution - http://www.alluxio.org/download
    # path to the jar alluxio-1.7.1-hadoop-2.7/client/alluxio-1.7.1-client.jar
    # https://github.com/Alluxio/alluxio
    "fs.alluxio.impl" = "alluxio.hadoop.FileSystem"
    # you can setup a block size for alluxio user property, either here or in the $SPARK_HOME/conf/spark-default.conf
    "alluxio.user.block.size.bytes.default" = "64MB"
    # access key, secret, endpoint might be defined in the config file or extracted fro the env variables.
    // "spark.hadoop.fs.s3a.access.key" = ""
    // "spark.hadoop.fs.s3a.secret.key" = ""
    // "spark.hadoop.fs.s3a.endpoint" = ""
  }


hr.emp-source = "s3a://mapreducelabs/spark/demo/hr/emp/emp.csv"
hr.emp-target = "alluxio://xxx:19998/emp2/emp.csv"



